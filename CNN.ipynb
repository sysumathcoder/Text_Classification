{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import random, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(string):\n",
    "    \"\"\"\n",
    "     Argument:\n",
    "             string: the string to be cleaned\n",
    "    \"\"\"\n",
    "    string = str(string)\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\"\\'m\", \" \\'m\", string)\n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"E:\\Text_Classification\\data\\Yelp\\yelp_review_full_csv\"\n",
    "TEXT = data.Field(tokenize='spacy',preprocessing=clean_data)\n",
    "LABEL = data.LabelField(dtype=torch.int8)\n",
    "tv_dataFields = [(\"label\", LABEL), (\"comment_text\", TEXT)]\n",
    "trn = data.TabularDataset.splits(path=file, train='test.csv',\\\n",
    "                                     format='csv',\\\n",
    "                                     skip_header=False, fields=tv_dataFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = trn[0].split(random_state=random.seed(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': '3',\n",
       " 'commet_text': \"'they' , 'were' , 'solid' , ' ' , 'the' , 'po' , 'boy' , 'was' , 'good' , ' '\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': '1',\n",
       " 'commet_text': ['I',\n",
       "  \"'m\",\n",
       "  'writing',\n",
       "  'this',\n",
       "  'review',\n",
       "  'about',\n",
       "  'our',\n",
       "  'stay',\n",
       "  '8/20',\n",
       "  '-',\n",
       "  '8/23',\n",
       "  '.',\n",
       "  'We',\n",
       "  'chose',\n",
       "  'to',\n",
       "  'celebrate',\n",
       "  'my',\n",
       "  'husband',\n",
       "  \"'s\",\n",
       "  'birthday',\n",
       "  'and',\n",
       "  'our',\n",
       "  'anniversary',\n",
       "  'at',\n",
       "  'the',\n",
       "  'MO',\n",
       "  '.',\n",
       "  'We',\n",
       "  'did',\n",
       "  'enjoy',\n",
       "  'the',\n",
       "  'pool',\n",
       "  'and',\n",
       "  'spa',\n",
       "  '.',\n",
       "  '\\\\n\\\\nHOWEVER',\n",
       "  ',',\n",
       "  'on',\n",
       "  'our',\n",
       "  'last',\n",
       "  'night',\n",
       "  'a',\n",
       "  'very',\n",
       "  'young',\n",
       "  ',',\n",
       "  'loud',\n",
       "  'group',\n",
       "  'of',\n",
       "  'party',\n",
       "  'people',\n",
       "  'checked',\n",
       "  'in',\n",
       "  'next',\n",
       "  'door',\n",
       "  '.',\n",
       "  'At',\n",
       "  'midnight',\n",
       "  ',',\n",
       "  'we',\n",
       "  'called',\n",
       "  'the',\n",
       "  'front',\n",
       "  'desk',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'if',\n",
       "  'they',\n",
       "  'could',\n",
       "  'speak',\n",
       "  'to',\n",
       "  'this',\n",
       "  'group',\n",
       "  'and',\n",
       "  'ask',\n",
       "  'them',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'down',\n",
       "  'the',\n",
       "  'LOUD',\n",
       "  'RAP',\n",
       "  'MUSIC',\n",
       "  'and',\n",
       "  'STOP',\n",
       "  'YELLING',\n",
       "  '.',\n",
       "  'The',\n",
       "  'front',\n",
       "  'desk',\n",
       "  'was',\n",
       "  'apologetic',\n",
       "  'and',\n",
       "  'called',\n",
       "  'their',\n",
       "  'room',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'them',\n",
       "  'to',\n",
       "  'be',\n",
       "  'quiet',\n",
       "  '.',\n",
       "  'The',\n",
       "  'noise',\n",
       "  'continued',\n",
       "  'for',\n",
       "  'another',\n",
       "  'half',\n",
       "  'hour.\\\\n\\\\nAround',\n",
       "  '5AM',\n",
       "  'we',\n",
       "  'were',\n",
       "  'woken',\n",
       "  'up',\n",
       "  'by',\n",
       "  'SHRIEKING',\n",
       "  'and',\n",
       "  'POUNDING',\n",
       "  'from',\n",
       "  'the',\n",
       "  'room',\n",
       "  'again',\n",
       "  '.',\n",
       "  'My',\n",
       "  'heart',\n",
       "  'was',\n",
       "  'racing',\n",
       "  'and',\n",
       "  'I',\n",
       "  'believed',\n",
       "  'a',\n",
       "  'woman',\n",
       "  'was',\n",
       "  'being',\n",
       "  'hurt',\n",
       "  '.',\n",
       "  'I',\n",
       "  'called',\n",
       "  'the',\n",
       "  'front',\n",
       "  'desk',\n",
       "  '.',\n",
       "  'They',\n",
       "  'quickly',\n",
       "  'responded',\n",
       "  'by',\n",
       "  'sending',\n",
       "  'several',\n",
       "  'men',\n",
       "  'to',\n",
       "  'the',\n",
       "  'room',\n",
       "  '.',\n",
       "  'A',\n",
       "  'young',\n",
       "  'girl',\n",
       "  '(',\n",
       "  'in',\n",
       "  'a',\n",
       "  'bikini',\n",
       "  ')',\n",
       "  'answered',\n",
       "  'the',\n",
       "  'door',\n",
       "  'and',\n",
       "  'assured',\n",
       "  'them',\n",
       "  'she',\n",
       "  'was',\n",
       "  'fine',\n",
       "  '.',\n",
       "  'I',\n",
       "  'walked',\n",
       "  'over',\n",
       "  '(',\n",
       "  'In',\n",
       "  'a',\n",
       "  'robe',\n",
       "  ')',\n",
       "  'and',\n",
       "  'told',\n",
       "  'the',\n",
       "  'girl',\n",
       "  'she',\n",
       "  'was',\n",
       "  'bring',\n",
       "  'very',\n",
       "  'rude',\n",
       "  'and',\n",
       "  'we',\n",
       "  'did',\n",
       "  \"n't\",\n",
       "  'appreciate',\n",
       "  'her',\n",
       "  'ruining',\n",
       "  'our',\n",
       "  'trip',\n",
       "  '.',\n",
       "  'She',\n",
       "  'then',\n",
       "  'closed',\n",
       "  'the',\n",
       "  'door',\n",
       "  '.',\n",
       "  'The',\n",
       "  'front',\n",
       "  'desk',\n",
       "  'then',\n",
       "  'asked',\n",
       "  'if',\n",
       "  'we',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'switch',\n",
       "  'rooms',\n",
       "  '.',\n",
       "  'No',\n",
       "  ',',\n",
       "  'at',\n",
       "  '5',\n",
       "  'am',\n",
       "  'I',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  '!',\n",
       "  '\\\\n\\\\nTHE',\n",
       "  'NOISE',\n",
       "  'continued',\n",
       "  ',',\n",
       "  'this',\n",
       "  'time',\n",
       "  'I',\n",
       "  'directly',\n",
       "  'dialed',\n",
       "  'the',\n",
       "  'room',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'her',\n",
       "  'to',\n",
       "  'please',\n",
       "  'have',\n",
       "  'the',\n",
       "  'group',\n",
       "  'stop',\n",
       "  'because',\n",
       "  'we',\n",
       "  'were',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  '.',\n",
       "  'She',\n",
       "  'proceeded',\n",
       "  'to',\n",
       "  'use',\n",
       "  'profanity',\n",
       "  'and',\n",
       "  'say',\n",
       "  'she',\n",
       "  'was',\n",
       "  'paying',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'money',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'there',\n",
       "  'and',\n",
       "  'could',\n",
       "  'do',\n",
       "  'what',\n",
       "  'she',\n",
       "  'wanted',\n",
       "  '.',\n",
       "  '\\\\n\\\\nEXAUSTED',\n",
       "  'and',\n",
       "  'DRAINED',\n",
       "  'we',\n",
       "  'packed',\n",
       "  'up',\n",
       "  'to',\n",
       "  'leave',\n",
       "  '.',\n",
       "  'As',\n",
       "  'a',\n",
       "  'consolation',\n",
       "  'a',\n",
       "  'breakfast',\n",
       "  'charge',\n",
       "  'was',\n",
       "  'removed',\n",
       "  'off',\n",
       "  'our',\n",
       "  'bill',\n",
       "  '.',\n",
       "  '\\\\n\\\\nSadly',\n",
       "  ',',\n",
       "  '$',\n",
       "  '1,200',\n",
       "  'later',\n",
       "  ',',\n",
       "  'I',\n",
       "  \"'m\",\n",
       "  'annoyed',\n",
       "  'and',\n",
       "  'tired',\n",
       "  '.',\n",
       "  'Terrible',\n",
       "  'ending',\n",
       "  'to',\n",
       "  'a',\n",
       "  'much',\n",
       "  'anticipated',\n",
       "  'stay',\n",
       "  '.',\n",
       "  'After',\n",
       "  'the',\n",
       "  'first',\n",
       "  'noise',\n",
       "  'disturbance',\n",
       "  ',',\n",
       "  'they',\n",
       "  'should',\n",
       "  'have',\n",
       "  'threatened',\n",
       "  'the',\n",
       "  'group',\n",
       "  'with',\n",
       "  'being',\n",
       "  'asked',\n",
       "  'to',\n",
       "  'leave',\n",
       "  '.',\n",
       "  'We',\n",
       "  'specifically',\n",
       "  'booked',\n",
       "  'the',\n",
       "  'MO',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'no',\n",
       "  'casino',\n",
       "  '/',\n",
       "  'no',\n",
       "  'club',\n",
       "  ',',\n",
       "  'relaxation',\n",
       "  'they',\n",
       "  'tout',\n",
       "  '.',\n",
       "  '\\\\n\\\\nWE',\n",
       "  'WILL',\n",
       "  'NOT',\n",
       "  'RETURN']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': '0',\n",
       " 'commet_text': '[\\'ok\\', \\',\\', \\'so\\', \\'i\\', \"\\'ve\", \\'been\\', \\'here\\', \\'before\\', \\'3\\', \\'years\\', \\'ago\\', \\'was\\', \\'very\\', \\'impressed\\', \\'since\\', \\'it\\', \\'was\\', \\'my\\', \\'first\\', \\'time\\', \\'to\\', \\'las\\', \\'vegas\\', \\'i\\', \\'was\\', \\'not\\', \\'impressed\\', \\'with\\', \\'the\\', \\'check\\', \\'in\\', \\'staff\\', \\'the\\', \\'ladies\\', \\'who\\', \\'answer\\', \\'the\\', \\'phone\\', \\'are\\', \\'rude\\', \\'and\\', \\'short\\', \\'i\\', \"\\'m\", \\'visiting\\', \\'vegas\\', \\'again\\', \\'next\\', \\'week\\', \\'and\\', \\'i\\', \\'booked\\', \\'an\\', \\'appointment\\', \\'with\\', \\'a\\', \\'lady\\', \\'who\\', \\'was\\', \\'a\\', \\'bit\\', \\'rude\\', \\'or\\', \\'not\\', \\'so\\', \\'friendly\\', \\'and\\', \\'when\\', \\'i\\', \\'called\\', \\'today\\', \\'to\\', \\'ask\\', \\'a\\', \\'question\\', \\'the\\', \\'lady\\', \\'was\\', \\'so\\', \\'unpleasant\\', \\'again\\', \\'so\\', \\'i\\', \\'just\\', \\'canceled\\', \\'my\\', \\'appointment\\', \\'all\\', \\'together\\', \\'customer\\', \\'service\\', \\'is\\', \\'very\\', \\'important\\', \\'in\\', \\'the\\', \\'salon\\', \\'and\\', \\'spa\\', \\'industry\\', \\'i\\', \\'would\\', \\'think\\', \\'the\\', \\'bellagio\\', \\'would\\', \\'hire\\', \\'some\\', \\'more\\', \\'friendly\\', \\'staff\\', \\'to\\', \\'be\\', \\'the\\', \\'face\\', \\'of\\', \\'their\\', \\'spa\\']'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['I',\n",
       "  'went',\n",
       "  'and',\n",
       "  'saw',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'last',\n",
       "  'night',\n",
       "  'after',\n",
       "  'being',\n",
       "  'coaxed',\n",
       "  'to',\n",
       "  'by',\n",
       "  'a',\n",
       "  'few',\n",
       "  'friends',\n",
       "  'of',\n",
       "  'mine',\n",
       "  '.',\n",
       "  'I',\n",
       "  \"'ll\",\n",
       "  'admit',\n",
       "  'that',\n",
       "  'I',\n",
       "  'was',\n",
       "  'reluctant',\n",
       "  'to',\n",
       "  'see',\n",
       "  'it',\n",
       "  'because',\n",
       "  'from',\n",
       "  'what',\n",
       "  'I',\n",
       "  'knew',\n",
       "  'of',\n",
       "  'Ashton',\n",
       "  'Kutcher',\n",
       "  'he',\n",
       "  'was',\n",
       "  'only',\n",
       "  'able',\n",
       "  'to',\n",
       "  'do',\n",
       "  'comedy',\n",
       "  '.',\n",
       "  'I',\n",
       "  'was',\n",
       "  'wrong',\n",
       "  '.',\n",
       "  'Kutcher',\n",
       "  'played',\n",
       "  'the',\n",
       "  'character',\n",
       "  'of',\n",
       "  'Jake',\n",
       "  'Fischer',\n",
       "  'very',\n",
       "  'well',\n",
       "  ',',\n",
       "  'and',\n",
       "  'Kevin',\n",
       "  'Costner',\n",
       "  'played',\n",
       "  'Ben',\n",
       "  'Randall',\n",
       "  'with',\n",
       "  'such',\n",
       "  'professionalism',\n",
       "  '.',\n",
       "  'The',\n",
       "  'sign',\n",
       "  'of',\n",
       "  'a',\n",
       "  'good',\n",
       "  'movie',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  'can',\n",
       "  'toy',\n",
       "  'with',\n",
       "  'our',\n",
       "  'emotions',\n",
       "  '.',\n",
       "  'This',\n",
       "  'one',\n",
       "  'did',\n",
       "  'exactly',\n",
       "  'that',\n",
       "  '.',\n",
       "  'The',\n",
       "  'entire',\n",
       "  'theater',\n",
       "  '(',\n",
       "  'which',\n",
       "  'was',\n",
       "  'sold',\n",
       "  'out',\n",
       "  ')',\n",
       "  'was',\n",
       "  'overcome',\n",
       "  'by',\n",
       "  'laughter',\n",
       "  'during',\n",
       "  'the',\n",
       "  'first',\n",
       "  'half',\n",
       "  'of',\n",
       "  'the',\n",
       "  'movie',\n",
       "  ',',\n",
       "  'and',\n",
       "  'were',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'tears',\n",
       "  'during',\n",
       "  'the',\n",
       "  'second',\n",
       "  'half',\n",
       "  '.',\n",
       "  'While',\n",
       "  'exiting',\n",
       "  'the',\n",
       "  'theater',\n",
       "  'I',\n",
       "  'not',\n",
       "  'only',\n",
       "  'saw',\n",
       "  'many',\n",
       "  'women',\n",
       "  'in',\n",
       "  'tears',\n",
       "  ',',\n",
       "  'but',\n",
       "  'many',\n",
       "  'full',\n",
       "  'grown',\n",
       "  'men',\n",
       "  'as',\n",
       "  'well',\n",
       "  ',',\n",
       "  'trying',\n",
       "  'desperately',\n",
       "  'not',\n",
       "  'to',\n",
       "  'let',\n",
       "  'anyone',\n",
       "  'see',\n",
       "  'them',\n",
       "  'crying',\n",
       "  '.',\n",
       "  'This',\n",
       "  'movie',\n",
       "  'was',\n",
       "  'great',\n",
       "  ',',\n",
       "  'and',\n",
       "  'I',\n",
       "  'suggest',\n",
       "  'that',\n",
       "  'you',\n",
       "  'go',\n",
       "  'see',\n",
       "  'it',\n",
       "  'before',\n",
       "  'you',\n",
       "  'judge',\n",
       "  '.'],\n",
       " 'label': 'pos'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <class 'torchtext.data.example.Example'>\n",
    "# <torchtext.data.example.Example object at 0x00000294BFF96278>\\\n",
    "test_data[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\")\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs,embedding_dim)) for fs in filter_sizes])\n",
    "        self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        x = x.permute(1, 0)\n",
    "                \n",
    "        #x = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1123,  0.3113,  0.3317,  ..., -0.4576,  0.6191,  0.5304],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.492 | Train Acc: 74.96% | Val. Loss: 0.340 | Val. Acc: 85.30% |\n",
      "| Epoch: 02 | Train Loss: 0.296 | Train Acc: 87.83% | Val. Loss: 0.300 | Val. Acc: 87.35% |\n",
      "| Epoch: 03 | Train Loss: 0.217 | Train Acc: 91.38% | Val. Loss: 0.271 | Val. Acc: 89.03% |\n",
      "| Epoch: 04 | Train Loss: 0.143 | Train Acc: 94.81% | Val. Loss: 0.270 | Val. Acc: 89.32% |\n",
      "| Epoch: 05 | Train Loss: 0.085 | Train Acc: 97.36% | Val. Loss: 0.289 | Val. Acc: 88.91% |\n",
      "| Epoch: 06 | Train Loss: 0.048 | Train Acc: 98.61% | Val. Loss: 0.332 | Val. Acc: 88.63% |\n",
      "| Epoch: 07 | Train Loss: 0.030 | Train Acc: 99.29% | Val. Loss: 0.368 | Val. Acc: 88.87% |\n",
      "| Epoch: 08 | Train Loss: 0.017 | Train Acc: 99.70% | Val. Loss: 0.387 | Val. Acc: 88.90% |\n",
      "| Epoch: 09 | Train Loss: 0.011 | Train Acc: 99.83% | Val. Loss: 0.434 | Val. Acc: 88.75% |\n",
      "| Epoch: 10 | Train Loss: 0.009 | Train Acc: 99.84% | Val. Loss: 0.458 | Val. Acc: 88.58% |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "    filepath = 'decoder-{}.ckpt'.format(epoch + 1)\n",
    "    torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('decoder-5.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.312 | Test Acc: 88.24% |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(sentence, min_len=5):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9371322393417358"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"This film is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
